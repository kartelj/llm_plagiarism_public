Typically, statistical methods in natural language processing demand a significant amount of labeled data and often a variety of auxiliary language tools, making them less feasible in settings with limited resources. This dissertation introduces a technique for creating statistical solutions for semantic processing of natural languages that have restricted resources. In these languages, there is not only a shortage of existing language resources, but also a limited capacity for generating new datasets, tools, and algorithms. The suggested technique prioritizes short texts due to their ubiquity in digital communication and the higher complexity in their semantic processing. The technique covers all stages in the development of statistical solutions, from text content collection, data annotation, to the creation, training, and assessment of machine learning models. Its application is demonstrated thoroughly on two semantic tasks - sentiment analysis and semantic textual similarity. The Serbian language is used as an instance of a language with limited resources, but the technique can also be applied to other languages in the same category. Apart from the general technique, this dissertation's contributions include the creation of a new, adaptable short-text sentiment annotation system, a new annotation cost-effectiveness metric, and several new semantic textual similarity models. The dissertation's results also comprise the production of the first publicly accessible annotated datasets of short texts in Serbian for sentiment analysis and semantic textual similarity tasks, the creation and assessment of numerous models for these tasks, and the first comparative assessment of multiple morphological normalization tools on short texts in Serbian.