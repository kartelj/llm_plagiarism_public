The main subject of interest in this doctoral thesis is model of classification, with the common goal of developing a model based on case-based reasoning (CBR) and intelligent selection of similarity measures, which will contribute to a more precise classification of new cases. It has been interesting to consider whether the domain knowledge, which can be expressed through preference functions, could be better exploited in such a way to improve the predictive performance of a CBR system. Additionally, the goal is to consider whether the model that using certain similarity measures for categorical data in combination with preference functions for similarity measuring between numerical data, can show better results than the traditional k-NN CBR model. Similarity measuring between the cases is an important part of each CBR model. Traditionally, in CBR models, for similarity measuring between numerical variables Euclidean metric is used, while for similarity measuring between categorical attributes overlap function is used. Preference theory functions could also be used for similarity measuring between the cases, particularly as they provide more opportunities to express preferences of the decision makers. Additionally, the results of classification models which use certain similarity measures for categorical attributes combined with the use of preference functions for numerical attributes, will be presented in this thesis. This thesis includes the optimization of attribute weights, as well as the results of models’ predictive power depending on the number of nearest neighbors which are taken into account. A genetic algorithm is used for setting the parameters of each preference function, as well as to set the attribute weights. The model has been evaluated on three different benchmark datasets of clients who require their credit application to be considered. Models’ accuracy have been measured with 10-fold cross-validation test. Cross-validation folds are generating by using the seed for randomizing the data. The experiment results show that the proposed approaches with preference theory functions can, in every case, outperform the traditional k-NN classifier, regardless of the applied similarity measures for categorical attributes. On the other hand, models which use preference theory functions, but different similarity measures for categorical data, showed that for each particular data set there was always a best suited technique, in which, besides the preference theory functions, an appropriate similarity measure for categorical attributes is also used.