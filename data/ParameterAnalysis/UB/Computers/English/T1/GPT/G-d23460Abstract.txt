Content generated by users on web forums is typically added more frequently than it's deleted or modified, which requires a distinction in its targeting during incremental crawling compared to general website page crawling. When new content is introduced to a forum, it can result in already existing content being relocated to new or already active pages. The task of incremental forum crawling is complex, as neglecting how the content is presented, distributed, and arranged could lead to previously indexed posts being transferred again in successive crawl cycles. Additionally, diverse forum technologies permit various navigational routes to most recent posts and a range of methods for displaying and arranging user-generated content.

This dissertation introduces the Structure-driven Incremental Forum crawler (SInFo), an advanced system specializing in targeting the most recent content in incremental forum crawling using leading optimization strategies and machine learning. The primary objective of the highlighted system is to evade recrawling content that has already been indexed, regardless of the technology employed. To realize this goal, the crawler utilizes Web Forum characteristics: (1) sorting method on the index and thread pages, and (2) existing navigational routes between pages offered by current Web Forum technology. Determining and standardizing the creation date of content, crucial in defining the type of sort, is complex and hence handled by machine learning models, which account for differing formats and languages. Navigational routes are identified by interpreting the URL format and scanning the target pages.

Research shows that applying these methods and techniques to target pages with the most recent content reduces the frequency of downloading redundant content and maximizes the usage of the current forum technology's navigational structure and paths. Tests were conducted on a broad variety of popular forum technologies as well as individual standalone forum technologies. SInFo has proven to be highly accurate with minimal redundant content transfers in each subsequent crawl cycle. Any remaining duplicates were primarily from pages that needed to be visited for accurate determination of the navigational path or to locate the correct URL. Though complex, the machine learning models performed well during the crawl, demonstrating high accuracy in date detection and normalization, and achieving a commendable F1-measure of 99%.