This doctorate thesis aims to develop a model that enhances the precision of case-based reasoning (CBR) classification using appropriate selection of similarity measures. The objective is to explore how domain knowledge, expressed through preference functions, can be effectively utilized to improve the predictive accuracy of a CBR system. We also aim to analyze if a model that employs distinct similarity measures for categorical data combined with preference functions for assessing numerical data similarity, can outdo the conventional k-NN CBR model.

The crux of each CBR model lies in measuring the similarities between individual cases. Conventionally, numerical similarity is measured utilizing the Euclidean metric, while the overlap function is used for categorical similarity assessment. The thesis hypothesizes that preference theory functions could offer an enhanced expression of decision-maker preferences whilst measuring case similarities.

Results from models that utilize designated similarity measures for categorical attributes paired with preference functions for numerical attributes will be presented. The thesis incorporates an examination of attribute weight optimization and the impact of the number of nearest neighbors considered on the modelsâ€™ predictive capabilities.

This investigation employs a genetic algorithm for defining preference function parameters and setting attribute weights. It evaluates the model using three different credit application datasets from clients and gauges its accuracy with a 10-fold cross-validation test.

The experiment outcomes indicate that the suggested approach, which harnesses preference theory functions, consistently surpasses the standard k-NN classifier irrespective of the categorical attribute similarity measures deployed. However, we observed that for each data set, a uniquely ideal technique presents itself; this employs both preference theory functions and a matching similarity measure for categorical attributes.