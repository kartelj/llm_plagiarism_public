Implementing statistical methods in natural language processing typically necessitates large amounts of labeled data and often various language assistance tools, which restricts their use in resource-poor environments. This dissertation offers a method for creating statistical systems for semantic processing in languages with limited resources. Such languages not only have scarce current language tools, but also limited abilities to generate new datasets and specialized tools and algorithms. The suggested method centres on brief texts due to their ubiquity in digital communication, along with the higher intricacy associated with their semantic processing. The method includes every step of creating statistical solutions, from gathering text content, annotating data, to the design, training, and testing of machine learning models. It's implemented extensively on two semantic jobs - sentiment examination and semantic text similarity. We use Serbian language as an object of a low-resource language, however, the method can be likewise applicable to other limited-resource languages. Besides the overarching method, this dissertation's contributions comprise a new, adjustable short-text sentiment annotation system, a fresh annotation cost-effectiveness measure, and several new semantic text similarity models. The dissertation's outcomes comprise the creation of the first publicly accessible annotated datasets of short texts in Serbian for performing sentiment analysis and semantic text similarity, the design and testing of multiple models on these tasks, and the first comparative testing of several morphological normalization tools on short Serbian texts.