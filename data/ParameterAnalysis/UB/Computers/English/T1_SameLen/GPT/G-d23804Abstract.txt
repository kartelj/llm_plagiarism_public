For efficiently incorporating emotional intelligence into complex artificial intelligence systems, dependable emotional state recognition is crucial, with the emotional content expressed in speech acting as a prime source of information about the speaker's emotional state. This article conducts a comparative study of frequently used speech signal attributes and classification techniques aimed at automating speaker emotion recognition. Following this, potential improvements for automated speech emotion recognition systems are explored. For the purpose of identifying codevectors for vector quantization, Discrete Hidden Markov models were enhanced using the QQ plot, with further enhancements also being considered. The capability for a more accurate representation of speech signals was scrutinized, extending the analysis to numerous attributes from various groups. The creation of large attribute sets commands the need for dimensionality reduction, where an alternative method centered around the Fibonacci number sequence is analyzed alongside other known methods. In conclusion, the potential for merging the strengths of various strategies into a unified system for automatic speech emotion recognition is contemplated, suggesting a parallel multi-classifier structure with a combinatorial rule that utilizes information on classifiers' properties in addition to individual ensemble classifiers' classification results. The paper also offers a suggestion for automatically establishing an arbitrary-sized classifier ensemble by employing dimensionality reduction based on the Fibonacci number sequence.