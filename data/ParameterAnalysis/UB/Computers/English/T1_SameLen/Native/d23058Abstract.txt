The phenomenon of emotional speech is rarely modeled in up to date speaker recognition research. The key challenge for a speaker recognition system is the difference in emotionalstateofaspeakerinthephaseofsystemtrainingandinthephaseofthesystemusage. In our research, different speaker modeling and classification algorithms were analyzed. In our experiments, Gaussian mixture models, as fundamental technique in speaker recognition, and i- vectors, as state-of-the-art technique for commercial use were evaluated. It was showed that by variating emotional content of speech and the number of sentences for speaker model training improves system robustness in recognition of speakers from both neutral and emotion impacted speech. Also, variation in model configuration by creating three models for each speaker was examined. Each of these models was trained by appropriate emotional speech grouped by emo- tion valence. The last part of research is dedicated to variation of speaker model structure by determining the number of components in Gaussian mixture based on subtractive clustering. The number of components was determined automatically from the training utterances for each speaker by using subtractive clustering. Theoretical dependencies of subtractive clustering parameters and the number of feature vectors in training sample, feature vector dimensionality and their distribution were induced. The results obtained showed that speaker can be modeled with fewer components in Gaussian mixture successfully, which opens space for further research of subtractive clustering application for speaker model training.