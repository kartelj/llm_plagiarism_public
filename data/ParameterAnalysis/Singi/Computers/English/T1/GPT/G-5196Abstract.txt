The process of identifying irregular activity on a computer network by contrasting unrecognized network traffic with a statistical model depicting normal behavior is referred to as anomaly detection. Binary classifiers, grounded in supervised machine learning, are apt for gauging normality. This research paper introduces five standard binary classifiers; k-nearest neighbors, weighted k-nearest neighbors, decision trees, support vector machines, and the feedforward neural network. A key issue with supervised learning is the substantial amount of data required to train highly precise classifiers. To mitigate the training duration with a slight compromise on the model's accuracy, a two-tier pre-processing technique is utilized. The first level involves selecting numeric attributes to downsize the dataset, followed by a unique normalization method that incorporates hyperbolic tangent function and the Levenberg-Marquardt algorithm's damping approach. The Kyoto 2006+ dataset, designed specifically for researching anomaly detection in computer networks and the only one accessible to the public, was employed to showcase the pre-processing's positive influence on the classifier's training duration and precision. Among the chosen classifiers, the feedforward neural network exhibited the highest processing speed, while the weighted k-nearest neighbor model was the most accurate. It is projected that the classifiers should, when operating simultaneously, identify either an anomaly or normal network traffic, which might not always be the case, thereby resulting in varying decisions about the anomaly and leading to a conflict. The detector that identifies conflicting decisions carries out a logical exclusive OR (XOR) operation on the classifiers' outputs. In case both classifiers detect an anomaly or identify traffic as normal at the same time, it is determined that no conflict has ensued, else a conflict is identified. The tally of conflicts presents an avenue for additional anomaly detection in computer network behavior.