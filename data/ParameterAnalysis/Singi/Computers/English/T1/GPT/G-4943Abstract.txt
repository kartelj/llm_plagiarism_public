This thesis examines methods to improve the detection accuracy of video content manipulated with Deepfake technology. An analysis was conducted on previous models, including XceptionNet, EfficientNetB, and EfficientNetV, designed specifically to detect videos altered using Deepfake's method. During the retraining process, parameters, such as the SingleDLCNN network, fold number and Hold-out technique parameters, were modified. A DataSet of over 6000 files was utilised, the vast majority of which were used to train the neural network, while the remaining ones were used for testing and verification purposes. The implementation of Cross-Validation extracted superior results, with an increase in accuracy achieved through weight optimisation or weight averaging. The outcome for every trained model is highlighted. The most successful result, 96.8% (FAR = 5.97%), was achieved with the EfficientNetB4 model. It is our belief that the achieved result validates the effectiveness of this training model. Looking forward, we hope to enhance the model and potentially bring it to market.