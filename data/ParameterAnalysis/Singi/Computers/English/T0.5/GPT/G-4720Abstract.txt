Culture's perpetuation shapes society, which in turn, is constructed through the enhancement and progression of culture and knowledge. Education serves as the tool for societal improvement, with the evaluation of acquired knowledge and practical skills being a critical aspect of it. Among all scientific disciplines, computer science frequently employs assessments to gauge students' practical skills. Various assessment techniques are employed in education, with the aim of refining these techniques to achieve precise and unbiased evaluations. Literature cites both outdated and current methods, including common ones like closed question type tests and practical work reviews and assessments. Tests are beneficial for gauging knowledge levels, while practical work reviews help determine practical skill levels. Both methods can be manually or automatically executed. Automated methods necessitate setups that allow for their execution without examiner involvement. Professional experience indicates that manual student assessment, regardless of method, struggles to maintain the necessary neutrality and accuracy. Thus, automated assessments are recommended. However, using these methods to measure both learned knowledge and acquired practical skills presents a challenge due to their incompatibility. This paper examines common problems found in literature reviews and seeks to devise an accurate, unbiased method for assessing students' practical skills in programming-related subjects. Over the course of the four-year study, two student generations were evaluated using two distinct solutions. One method employed an electronic multichoice test to measure knowledge, while the other analyzed the correctness of practical work. The paper provides answers to several research questions, derived from data analysis using the two assessment methods. The research utilized quantitative and qualitative analysis methods to review the collected data. It also includes case studies of the assessment methods used to perform these evaluations and collect data over the study's duration. The paper explores the potential of creating a tool that can automate the review and evaluation of practical works, thereby replacing the teacher as an examiner. It also compares the assessment results' similarity from both methods, the efficacy of tests in determining practical skills levels, and the possibility of providing unbiased assessments without examiner influence. The paper discusses the analyzed data and research findings. The study proposes a method for objectively and accurately assessing practical skills levels in programming-related computer science subjects at the bachelor's academic level. It presents solutions to achieve this goal and contributes both scientifically and practically.