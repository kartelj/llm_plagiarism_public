Anomaly detection involves identifying unusual computer network behavior by contrasting unfamiliar network traffic with a statistical model of regular network behavior. Binary classifiers, which are based on supervised machine learning, are effective tools for detecting normality. This dissertation introduces five common binary classifiers: k-nearest neighbors, weighted k-nearest neighbors, decision trees, support vector machines, and feedforward neural networks. The primary challenge with supervised learning is the substantial amount of data required to train high-accuracy classifiers. To lessen the training time while minimally impacting the model's precision, a two-step pre-processing method is implemented. The first step involves selecting numeric attributes to decrease the dataset size. The second step introduces a unique normalization technique based on the hyperbolic tangent function and the Levenberg-Marquardt algorithm's damping strategy. The Kyoto 2006+ dataset, the only publicly accessible dataset of real-world network traffic solely for anomaly detection research in computer networks, was utilized to showcase the positive effects of this pre-processing on classifier training time and accuracy. Among the chosen classifiers, the feedforward neural network exhibited the fastest processing speed, while the weighted k-nearest neighbor model was the most precise. It is assumed that when the classifiers operate simultaneously, they should either detect an anomaly or normal network traffic. However, this is not always the case, leading to disagreements about the anomaly. The conflict detection detector uses an exclusive OR (XOR) operation on the classifier outputs. If both classifiers detected an anomaly or recognized traffic as normal at the same time, it was concluded that no conflict had arisen. Otherwise, a conflict was identified. The number of conflicts discovered provides an additional opportunity to detect changes in computer network behavior.