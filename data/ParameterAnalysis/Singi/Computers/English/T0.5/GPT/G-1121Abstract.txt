This study investigates the extraction of information from multimodal business documents in a desktop setting. A document communicates information through various modes such as text, layout/style, and images. For instance, scientific papers often include figures to demonstrate experimental findings, and the title of a paper typically uses a different font size than the main text. Traditionally, information retrieval (IR) relied solely on text for indexing and retrieval. However, with the advent of the Internet and Digital Libraries, it has become increasingly crucial to devise IR methods for smart indexing and retrieval of multimodal documents. Indexing and retrieval constitute two crucial elements of an IR system. Indexing entails describing documents using an index language, while retrieval involves using indexing results to locate documents relevant to a user's query. Text and image modes employ different indexing and retrieval methods. Single-mode IR, which uses either text or images, has its limitations. Multimodal IR seeks to address these shortcomings by integrating various modes.