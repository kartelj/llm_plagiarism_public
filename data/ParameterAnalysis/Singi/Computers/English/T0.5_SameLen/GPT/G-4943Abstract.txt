This thesis scrutinizes the techniques for more precise identification of video content tampered with using the Deepfake method. Prior models designed for detecting Deepfake video tampering, along with their models and parameters, were examined. These models include XceptionNet, EfficientNetB, and EfficientNetV. During the retraining phase, changes were made to the SingleDLCNN network, the fold count, and the Hold-out technique parameters. A DataSet comprising over 6000 files was utilized, with most of them used for training the neural network and the rest for testing and validation. Cross-Validation was employed to derive the best outcomes, and accuracy was enhanced by weight averaging, or weight optimization. The outcomes for all trained models are showcased. The top performance was achieved with the EfficientNetbB4, at 96.8% (FAR = 5.97%). We are confident that this result demonstrates the effectiveness of this training model. Moving forward, we aim to refine the model and eventually bring it to market.