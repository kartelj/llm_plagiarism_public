Anomaly detection involves identifying suspicious activity in a computer network by comparing unfamiliar network traffic to a statistical model of regular network behavior. Binary classifiers, which are based on supervised machine learning, are suitable for detecting normality. This dissertation introduces five conventional binary classifiers: k-nearest neighbors, weighted k-nearest neighbors, decision trees, support vector machines, and feedforward neural network. The primary issue with supervised learning is that it requires substantial data to train high-accuracy classifiers. A two-phase pre-processing step is used to decrease training time while maintaining model accuracy. The first phase involves selecting numeric attributes to reduce the dataset. The second phase introduces a unique normalization method that utilizes the hyperbolic tangent function and the damping strategy of the Levenberg-Marquardt algorithm. The Kyoto 2006+ dataset, the only publicly accessible dataset of real-world network traffic intended exclusively for anomaly detection research in computer networks, was used to illustrate the positive impact of such pre-processing on classifier training time and accuracy. Among all the chosen classifiers, the feedforward neural network has the fastest processing speed, while the weighted k-nearest neighbor model was found to be the most precise. The expectation is that the classifiers should either detect an anomaly or normal network traffic when working concurrently, which is not always the case, leading to a discrepancy in the anomaly decision. The conflicting decision detector applies a logical exclusive OR (XOR) operation on the classifier outputs. If both classifiers detected an anomaly or identified traffic as normal simultaneously, their decision was considered conflict-free. Otherwise, a conflict is identified. The number of conflicts detected offers a chance for additional detection of changes in computer network behavior.