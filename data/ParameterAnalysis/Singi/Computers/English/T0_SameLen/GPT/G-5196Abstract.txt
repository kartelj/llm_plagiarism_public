Identifying unusual computer network activity, or anomaly detection, involves comparing unfamiliar network traffic to a statistical model of regular network behavior. Binary classifiers, which are based on supervised machine learning, are effective tools for detecting normality. This paper introduces five common binary classifiers: k-nearest neighbors, weighted k-nearest neighbors, decision trees, support vector machines, and feedforward neural network. The primary issue with supervised learning is the large amount of data required to train high-precision classifiers. To decrease training time without significantly impacting model accuracy, a two-step pre-processing procedure is implemented. The first step involves selecting numeric attributes to downsize the dataset. The second step introduces a unique normalization method that utilizes the hyperbolic tangent function and the Levenberg-Marquardt algorithm's damping strategy. The Kyoto 2006+ dataset, the only publicly accessible dataset of real-world network traffic designed exclusively for anomaly detection research in computer networks, was employed to illustrate the positive effects of such pre-processing on classifier training time and accuracy. Among all the chosen classifiers, the feedforward neural network demonstrated the fastest processing speed, while the weighted k-nearest neighbor model was the most accurate. The expectation is that the classifiers, when operating simultaneously, should either identify an anomaly or normal network traffic. However, this is not always the case, leading to conflicting decisions about the anomaly. The conflict detection detector applies a logical exclusive OR (XOR) operation to the classifier outputs. If both classifiers detected an anomaly or identified traffic as normal at the same time, it was determined that no conflict had occurred. Otherwise, a conflict is identified. The number of conflicts detected offers a chance for further detection of changes in computer network behavior.