This dissertation analyses the methods for more accurate detection of video materials manipulated using the Deepfake technique. Previous models intended for detecting video manipulation through the Deepfake technique, and their models and parameters were analysed. These models are XceptionNet, EfficientNetB and EfficientNetV. The SingleDLCNN network, the fold number and the value for the Hold-out technique parameters were changed in the retraining process. A DataSet with over 6000 files was used, with the majority used to train the neural network and the rest for testing and validation. Cross-Validation was used to extract the best results, and the accuracy was increased by weight averaging, i.e., by weight optimization. The results for all trained models are presented. The best result was achieved using the EfficientNetbB4. 96.8% (FAR = 5.97%). We believe that the achieved result proves the quality of this training model. For future work, we plan to improve the model and to eventually commercialise it. 