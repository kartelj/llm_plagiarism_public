'This thesis explores the strategies for precise identification of video content altered via the Deepfake approach. Past models aimed at identifying video alterations through the Deepfake approach, and their models and settings were assessed. These models consist of XceptionNet, EfficientNetB and EfficientNetV. In the retraining phase, adjustments were made to the SingleDLCNN network, the fold count and the Hold-out technique parameters. Over 6000 files comprised the DataSet used, with the bulk of these being used to train the neural network, the remainder for testing and validation. Optimal results were extracted through Cross-Validation and improved accuracy was achieved via weight averaging, also known as weight optimization. The results for all trained models are demonstrated. The finest outcome came from EfficientNetbB4 with a 96.8% accuracy (FAR = 5.97%). We are of the opinion that this outcome testifies to the efficacy of this training model. For ongoing research, our aim is to enhance the model and possibly introduce it into the market.