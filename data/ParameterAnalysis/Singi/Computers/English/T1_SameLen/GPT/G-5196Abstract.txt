Identifying unusual computer network activity, or anomaly detection, involves comparing unfamiliar network traffic to a statistical model of standard network behavior. Normality detection is well-suited to binary classifiers that utilize supervised machine learning. In this paper, we explore five common binary classifiers: k-nearest neighbors, weighted k-nearest neighbors, decision trees, support vector machines, and feedforward neural networks. However, a significant issue with supervised learning is the large amount of data necessary for training precise classifiers. A two-stage pre-processing step is implemented to decrease training duration without significantly impacting model accuracy. Firstly, numeric attributes are highlighted to reduce the dataset size. The second stage introduces an innovative normalization technique using the hyperbolic tangent function and Levenberg-Marquardt algorithm's damping approach. We used the Kyoto 2006+ dataset, the only open-source real-world network traffic dataset created exclusively for computer network anomaly detection research, to highlight the positive effect of pre-processing on training duration and model precision. The fastest classifier was the feedforward neural network, while the most precise was the model using the weighted k-nearest neighbor. The working hypothesis is that when classifiers operate in tandem, they should either detect an anomaly or recognize standard network traffic. However, differing decisions occasionally emerge, indicating a conflict. An exclusive OR (XOR) operation is applied to the classifier outputs by the conflict detection system. If both classifiers identified an anomaly or standard traffic simultaneously, no conflict was identified. In all other instances, a conflict was detected. The amount of detected conflicts offers potential for additional detection of computer network behavior variations.