Research in human-computer interaction incorporates a multidisciplinary approach, drawing from fields such as computer science, psychology, sociology, cognitive sciences, and design. Modern interfaces facilitate interaction through a variety of sensors like mouse, keyboard, eyetracker, EEG, pulse monitor, heart rate monitor, etc. The focus of this research is the application of artificial intelligence in analyzing and assessing human-computer interaction and cognitive performance of respondents. The system's superior data analysis speed allows for real-time feedback, making it an active participant in the interaction.

The feasibility of developing an AI model for collecting and analyzing human-computer interaction data was demonstrated using four cognitive performance assessments: Wisconsin Card Sorting Test (WSCT), Visual Short Term Working Memory Test (VSTWMT), mTutor Test, and the AC Test. Individual client applications were developed for each experiment, capable of connecting to sensor applications via the HCI-MAP Synchronization Platform. Data was collected using three sensors: an EEG device, an eye tracking device, and a computer mouse. Independent sensor applications were created for the EEG and eye tracking device to allow for data aggregation and joint processing.

Our research findings showed some deviation from reference values in the WCS test results of our participant group. However, there were no significant discrepancies in errors in maintaining set. Visual short-term memory (VSTM), the ability to remember small amounts of visual information for a short period, was tested in two sessions. The EEG data was classified using four algorithms: Naive Bayes, Support Vector, KNN, and Random Forest, achieving over 90% accuracy in classifying the order and type of images presented.

The mTutor platform experiment aimed to develop an AI model that could accurately reflect respondents' real knowledge in electronic assessments. While no strong correlation was found between any individual parameter and response accuracy, the experiment showed that the emotional state of subjects could be influenced by the type of questions asked.

The AC test assessed attention levels, or the ability to distinguish important stimuli from distractions. A high correlation between gaze position and mouse cursor position was observed, suggesting that one sensor's interaction could be approximated using data from the other. 

In conclusion, our research indicates that AI can effectively analyze human-computer interaction, potentially yielding results as good as or better than human analysis. Distributed solutions can be implemented for system synchronization and real-time feedback. AI can also assess users' cognitive performance through automated analysis.