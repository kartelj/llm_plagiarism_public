This thesis examines the techniques for more precise identification of video content manipulated with the Deepfake method. It reviews previous models designed for detecting such video manipulation, including their models and parameters. These models include XceptionNet, EfficientNetB, and EfficientNetV. During the retraining process, adjustments were made to the SingleDLCNN network, the fold number, and the Hold-out technique parameters. A DataSet of over 6000 files was utilized, with the majority being used for neural network training and the remainder for testing and validation. The best results were obtained using Cross-Validation, and accuracy was enhanced through weight averaging, or weight optimization. The outcomes for all trained models are provided. The most successful result was obtained with the EfficientNetbB4, achieving 96.8% accuracy (FAR = 5.97%). We are confident that this result demonstrates the effectiveness of our training model. In future, we aim to refine the model and eventually bring it to market.