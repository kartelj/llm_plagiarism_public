Anomaly detection involves identifying unusual computer network behavior by comparing unfamiliar network traffic to a statistical model of regular network behavior. Binary classifiers, based on supervised machine learning, are suitable for detecting normality. This study introduces five standard binary classifiers: k-nearest neighbors, weighted k-nearest neighbors, decision trees, support vector machines, and feedforward neural network. The primary issue with supervised learning is the large amount of data required to train high-precision classifiers. To decrease the training time without significantly affecting the models' accuracy, a two-step pre-processing procedure is implemented. The first step involves selecting numeric attributes to minimize the dataset, while the second introduces a unique normalization method based on the hyperbolic tangent function and the Levenberg-Marquardt algorithm's damping strategy. The Kyoto 2006+ dataset, the only publicly accessible dataset of real-world network traffic designed exclusively for anomaly detection research in computer networks, was utilized to illustrate the pre-processing's positive effect on classifier training time and accuracy. Among all the chosen classifiers, the feedforward neural network had the fastest processing speed, while the weighted k-nearest neighbor model was the most accurate. The expectation is that the classifiers should either detect an anomaly or normal network traffic when working simultaneously, but this is not always the case, leading to conflicting decisions about the anomaly. The conflict detection detector applies a logical exclusive OR (XOR) operation to the classifiers' outputs. If both classifiers detected an anomaly or identified traffic as normal simultaneously, it was determined that no conflict had occurred. Otherwise, a conflict is detected. The number of conflicts detected offers a chance for additional detection of changes in computer network behavior.