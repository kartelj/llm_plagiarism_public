This study focuses on the investigation of information extraction from multimodal business documents within a desktop setting. A document communicates information through various modes, such as text, layout/style, and images. For instance, scientific articles often include figures to demonstrate experimental findings, and the title typically has a different font size compared to the main text. The conventional method of Information Retrieval (IR) involves indexing and retrieval using only text. However, with the evolution of the internet and digital libraries, it has become increasingly crucial to develop IR methods for smart indexing and retrieval of multimodal documents. Indexing and retrieval are two crucial elements of an IR system. Indexing involves describing documents using an index language, while retrieval involves using the indexing results to find documents relevant to a user's query. Different techniques are used for indexing and retrieval of text and image modalities. Single-modality IR, which uses either text or images, has its limitations. Multimodal IR seeks to address these limitations by integrating both modalities.